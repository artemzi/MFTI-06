{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструкция по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#placeholder\" class=\"btn btn-default\" data-toggle=\"collapse\">Развернуть список</a>\n",
    "</div>\n",
    "<div id=\"placeholder\" class=\"collapse\">\n",
    "<ol>\n",
    "    <li>Здесь и далее оценка качества будет выполняться с помощью cross_val_score с cv=5 и остальными параметрами по умолчанию. Оцените среднее качество ( .mean() ) и стандартное отклонение ( .std() ) по fold'ам для: а) pipeline из CountVectorizer() и LogisticRegression(), б) pipeline из TfidfVectorizer() и LogisticRegression(). В соответствующем пункте задания выпишите через пробел среднее в п. а, отклонение в п. а, среднее в п.б и отклонение в п. б [ссылка](#1)</li>\n",
    "    <li>Попробуйте позадавать параметр min_df у CountVectorizer. Оцените качество вашего классикатора с min_df=10 и с min_df=50 [ссылка](#2)</li>\n",
    "    <li>Поперебирайте классификатор, используемый после CountVectorizer. И vectorizer и классификатор берите с параметрами по умолчанию. Сравните результаты для LogisticRegression, LinearSVC и SGDClassifier. Выпишите в ответе на соответствующий вопрос самое худшее качество из получившихся [ссылка](#3)</li>\n",
    "    <li>Подготовьте список стоп-слов с помощью nltk.corpus.stopwords.words('english'), посмотрите на его элементы, и передайте его в соответствующий параметр CountVectorizer. В sklearn также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе [ссылка](#4)</li>\n",
    "    <li>Попробуйте в CountVectorizer добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. Полученные два числа запишите через пробел в ответе на соответствующий вопрос [ссылка](#5)</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.words(fileids=[f]) for f in posids]\n",
    "\n",
    "feedbacks = np.append(negfeats, posfeats)\n",
    "for indx, elm in enumerate(feedbacks):\n",
    "    feedbacks[indx] = \" \".join(elm)\n",
    "\n",
    "n, p = len(negfeats), len(posfeats)\n",
    "negative, positive = np.zeros(n), np.ones(p)\n",
    "\n",
    "classes = np.append(negative, positive)\n",
    "\n",
    "cv = 5 # from task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание #1 <a id='1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.45 s, sys: 52 ms, total: 5.5 s\n",
      "Wall time: 5.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vct = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "score = model_selection.cross_val_score(pipe, feedbacks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83602165039290777, 0.015309139640513638)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.07 s, sys: 32 ms, total: 4.1 s\n",
      "Wall time: 4.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tct = TfidfVectorizer()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('vectorizer', tct),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "score_tf = model_selection.cross_val_score(pipe, feedbacks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81351111590632552, 0.01035604041249499)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tf.mean(), score_tf.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('subm/w02s01.txt', 'w+') as f:\n",
    "    f.write(\" \".join([str(score.mean()), str(score.std()), str(score_tf.mean()), str(score_tf.std())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание #2 <a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vct10 = CountVectorizer(min_df=10)\n",
    "vct50 = CountVectorizer(min_df=50)\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe10 = Pipeline(steps = [\n",
    "    ('vectorizer', vct10),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "pipe50 = Pipeline(steps = [\n",
    "    ('vectorizer', vct50),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "score10 = model_selection.cross_val_score(pipe10, feedbacks, classes)\n",
    "score50 = model_selection.cross_val_score(pipe50, feedbacks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('subm/w02s02.txt', 'w+') as f:\n",
    "    f.write(\" \".join([str(score10.mean()), str(score50.mean())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание #3 <a id='3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 60 ms, total: 14.9 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vct = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "svc = LinearSVC()\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "pipe_clf = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', svc)\n",
    "])\n",
    "\n",
    "pipe_sgd = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', sgd)\n",
    "])\n",
    "\n",
    "clf_score = model_selection.cross_val_score(pipe_clf, feedbacks, classes)\n",
    "svc_score = model_selection.cross_val_score(pipe_svc, feedbacks, classes)\n",
    "sgd_score = model_selection.cross_val_score(pipe_sgd, feedbacks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('subm/w02s03.txt', 'w+') as f:\n",
    "    f.write(str(min(clf_score.mean(), svc_score.mean(), sgd_score.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание #4 <a id='4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8270171368973763\n"
     ]
    }
   ],
   "source": [
    "vct = CountVectorizer(stop_words=stop)\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "score = model_selection.cross_val_score(pipe, feedbacks, classes)\n",
    "print(\"{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8345141548734363\n"
     ]
    }
   ],
   "source": [
    "vct = CountVectorizer(stop_words='english')\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "score = model_selection.cross_val_score(pipe, feedbacks, classes)\n",
    "print(\"{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = [0.8270171368973763, 0.8345141548734363]\n",
    "\n",
    "with open('subm/w02s04.txt', 'w+') as f:\n",
    "    f.write(\" \".join([str(i) for i in result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание #5 <a id='5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_bigrams = { x : i for i, x in enumerate(stop) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8270171368973763\n"
     ]
    }
   ],
   "source": [
    "vct = CountVectorizer(stop_words=words_bigrams)\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "score = model_selection.cross_val_score(pipe, feedbacks, classes)\n",
    "print(\"{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8205031378684073\n"
     ]
    }
   ],
   "source": [
    "vct = CountVectorizer(analyzer='char_wb', ngram_range=(3, 5))\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('vectorizer', vct),\n",
    "    ('logistic', clf)\n",
    "])\n",
    "\n",
    "score = model_selection.cross_val_score(pipe, feedbacks, classes)\n",
    "print(\"{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = [0.8270171368973763, 0.8205031378684073]\n",
    "\n",
    "with open('subm/w02s05.txt', 'w+') as f:\n",
    "    f.write(\" \".join([str(i) for i in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
