{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree\n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, RidgeClassifierCV \n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"classifier\", classifier)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим из тестовых данных xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"sss.xml\",'w')\n",
    "f.write('<root>\\n')\n",
    "f2 = open('test.csv','r')\n",
    "lines = f2.readlines()\n",
    "for line in lines:\n",
    "    f.write(line)\n",
    "f2.close()\n",
    "f.write('</root>')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = xml.etree.ElementTree.parse('sss.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_raw = e.findall('review')\n",
    "test_reviews = np.array([x.text for x in reviews_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем честно украденные у Яндекса данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = pickle.load(open('texts.pkl','rb'))\n",
    "labels = pickle.load(open('labels.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Подбираем более менее пристойную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "0.791111111111\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "0.784444444444\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifier'>\n",
      "0.795555555556\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifierCV'>\n",
      "0.785555555556\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "0.795555555556\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "0.8\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifier'>\n",
      "0.802222222222\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifierCV'>\n",
      "0.802222222222\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vctr in [CountVectorizer, TfidfVectorizer]:\n",
    "    for trfr in [TfidfTransformer]:\n",
    "        for clfr in [LogisticRegression, SGDClassifier, RidgeClassifier, RidgeClassifierCV]:\n",
    "            print(vctr)\n",
    "            print(trfr)\n",
    "            print(clfr)\n",
    "            print(cross_val_score(text_classifier(vctr(), trfr(), clfr()), texts, labels).mean())\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Попробуем подобрать параметры для наиболее удачной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RidgeClassifierCV()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 4000, 6000, 8000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__cv': (None, 3),\n",
    "    'clf__normalize': (True, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "('pipeline:', ['vect', 'tfidf', 'clf'])\n",
      "parameters:\n",
      "{'clf__cv': (None, 3),\n",
      " 'clf__normalize': (True, False),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 4000, 6000, 8000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3))}\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed: 17.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1042.771s\n",
      "()\n",
      "Best score: 0.834\n",
      "Best parameters set:\n",
      "\tclf__cv: None\n",
      "\tclf__normalize: False\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(texts, labels)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_i....0, 10.0), class_weight=None, cv=None,\n",
       "         fit_intercept=True, normalize=False, scoring=None))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = text_classifier(\n",
    "    TfidfVectorizer(max_df=0.75, ngram_range=(1, 3)),\n",
    "    TfidfTransformer(norm='l1'),\n",
    "    RidgeClassifierCV()\n",
    ")\n",
    "model.fit(texts,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Трём магический шар и получаем предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,\n",
       "        1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
       "        1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Записываем в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for x in model.predict(test_reviews):\n",
    "    if x > 0:\n",
    "        t.append('pos')\n",
    "    else:\n",
    "        t.append('neg')\n",
    "        \n",
    "result = pd.DataFrame(data = t, columns=['y'])\n",
    "\n",
    "result.to_csv('result.csv',index_label=['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "kaggle 0.82 So sad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Попробуем лемматизировать наши тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_word(word):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    p = morph.parse(word)[0]\n",
    "    return p.normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_list(lst):\n",
    "    words_list = [re.sub('\\W', ' ', x, flags=re.UNICODE).split() for x in lst]\n",
    "    reviews_norm = []\n",
    "    for words in words_list:\n",
    "        words_norm_list = []\n",
    "        for word in words:\n",
    "            nw = norm_word(word)\n",
    "            words_norm_list.append(nw)\n",
    "        reviews_norm.append(words_norm_list)\n",
    "    result = [(' ').join(x) for x in reviews_norm]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_reviews_norm = norm_list(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ужасно слабый аккумулятор это основной минус это аппарат разряжаться буквально за пара часы при включить wifi и на макс подсветка например если играть или смотреть видео следовательно использовать можно только если есть постоянный возможность подзарядиться качество звук через динамик далеко не на высота наблюдаться незначительный тормоз в некоторый приложение и вообще в меню очень мало встроить память а приложение устанавливаться именно туда с это связанный неудобство нужно постоянно переносить они на карта память несколько неудобно что нету отдельный кнопка для фото подумывать купить батарея больший ёмкость мб что нибыть измениться\n"
     ]
    }
   ],
   "source": [
    "print(test_reviews_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выглядит неплохо, попробуем лемматизировать отзывы с Яндекса.\n",
    "Интересно, сколько это займёт времени?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15h 41min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts_norm = norm_list(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "шестнадцать часов, ёлы-палы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подыщем модель посимпатичней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "0.798888888889\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "0.79\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifier'>\n",
      "0.801111111111\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifierCV'>\n",
      "0.795555555556\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "0.814444444444\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "0.793333333333\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifier'>\n",
      "0.825555555556\n",
      "\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfTransformer'>\n",
      "<class 'sklearn.linear_model.ridge.RidgeClassifierCV'>\n",
      "0.798888888889\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vctr in [CountVectorizer, TfidfVectorizer]:\n",
    "    for trfr in [TfidfTransformer]:\n",
    "        for clfr in [LogisticRegression, SGDClassifier, RidgeClassifier, RidgeClassifierCV]:\n",
    "            print(vctr)\n",
    "            print(trfr)\n",
    "            print(clfr)\n",
    "            print(cross_val_score(text_classifier(vctr(), trfr(), clfr()), texts_norm, labels).mean())\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(texts_norm, open(\"texts_norm.pkl\",\"wb\"))\n",
    "pickle.dump(test_reviews_norm, open(\"test_norm.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на всякий случай сохранили наши лемматизированные отзывы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а теперь подбираем параметры лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RidgeClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 4000, 6000, 8000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__normalize': (True, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "('pipeline:', ['vect', 'tfidf', 'clf'])\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05, 1e-06),\n",
      " 'clf__normalize': (True, False),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 4000, 6000, 8000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3))}\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed: 15.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 910.601s\n",
      "()\n",
      "Best score: 0.840\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__normalize: False\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(texts_norm, labels)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_norm = text_classifier(\n",
    "    TfidfVectorizer(ngram_range=(1, 2)),\n",
    "    TfidfTransformer(),\n",
    "    RidgeClassifier(alpha=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_id...tercept=True, max_iter=None, normalize=False,\n",
       "        random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_norm.fit(texts_norm, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_norm = model_norm.predict(test_reviews_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for x in res_norm:\n",
    "    if x > 0:\n",
    "        t.append('pos')\n",
    "    else:\n",
    "        t.append('neg')\n",
    "        \n",
    "result = pd.DataFrame(data = t, columns=['y'])\n",
    "\n",
    "result.to_csv('result_norm.csv',index_label=['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат на kaggle 0.9\n",
    "\n",
    "Совсем другое дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
