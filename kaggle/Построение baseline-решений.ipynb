{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.virtualenvs/python3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/artem/.virtualenvs/python3.6/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#placeholder\" class=\"btn btn-default\" data-toggle=\"collapse\">Предварительные инструкции (clickable)</a>\n",
    "</div>\n",
    "<div id=\"placeholder\" class=\"collapse\">\n",
    "<ol>\n",
    "    <li>Во-первых, на разработку baseline-модели не должно уходить много времени (это требование исходит из оценок затрат на проект в целом - большую часть времени все же нужно потратить на основное решение), процесс должен быть простым, на подавляющем большинстве этапов должны использоваться готовые протестированные инструменты. Все это приводит к тому, что baseline-модели - это дешевый способ сделать грубую оценку потенциально возможного качества модели, при построении которого вероятность допущения ошибок относительно невелика.</li>\n",
    "    <li>Во-вторых, использование моделей разного типа при построении baseline'ов позволяет на раннем этапе сделать предположения о том, какие подходы являются наиболее перспективными и приоритизировать дальнейшие эксперименты.</li>\n",
    "    <li>Наличие baseline-моделей позволяет оценить, какой прирост качества дают различные преобразования, усложнения, оптимизации и прочие активности, которые вы предпринимаете для построения финального решения.\n",
    "</li>\n",
    "    <li>Наконец, если после построение сложного решения оценка его качества будет очень сильно отличаться от оценки качества baseline-моделей, то это будет хорошим поводом поискать в решении ошибки.\n",
    "</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При желании, можно сразу перейти к результату первого сабмита: ([ссылка](#1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/products_sentiment_train.tsv', delimiter='\\t', header=None, names=['sentences', 'p/n'])\n",
    "df_test = pd.read_csv('data/products_sentiment_test.tsv', delimiter='\\t', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "sentences    2000 non-null object\n",
      "p/n          2000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # повезло, в данных нет пропусков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала попробуем выделить признаки на основе счетчика слов и классифицировать их несколькими способами.\n",
    "(LogisticRegression, SGDClassifier, LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_check(vectorizer, classifier): # just helper function\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('vct', vectorizer),\n",
    "        ('clf', classifier)\n",
    "    ])\n",
    "    \n",
    "    # тут небольшой читинг, параметр фолдов для кросс валидации уже подобранн методом научного тыка.\n",
    "    score = model_selection.cross_val_score(pipe, df.sentences, df['p/n'], cv=15, scoring='accuracy')\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV + LogisticRegression: 0.7729754621742053\n",
      "CV + SGDClassifier:      0.7455036845845958\n",
      "CV + LinearSVC:          0.7484698290275666\n"
     ]
    }
   ],
   "source": [
    "print(\"CV + LogisticRegression: {}\".format(do_check(CountVectorizer(), LogisticRegression())))\n",
    "print(\"CV + SGDClassifier:      {}\".format(do_check(CountVectorizer(), SGDClassifier())))\n",
    "print(\"CV + LinearSVC:          {}\".format(do_check(CountVectorizer(), LinearSVC())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картина, которую мы наблюдаем с параметрами по умолчанию мягко говоря бездарная и что с этим делать пока не понятно, но попробуем то же, только на этот раз выделим признаки на основе частотности слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV + LogisticRegression: 0.7740194561482856\n",
      "TV + SGDClassifier:      0.7699714006862474\n",
      "TV + LinearSVC:          0.7699642026821917\n"
     ]
    }
   ],
   "source": [
    "print(\"TV + LogisticRegression: {}\".format(do_check(TfidfVectorizer(), LogisticRegression())))\n",
    "print(\"TV + SGDClassifier:      {}\".format(do_check(TfidfVectorizer(), SGDClassifier())))\n",
    "print(\"TV + LinearSVC:          {}\".format(do_check(TfidfVectorizer(), LinearSVC())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат несколько улучшился, но он по прежнему бездарен. Нужно подбирать параметры. Но мы все еще можем испытать метод ближайших соседей и деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result with CV: 0.6589881533322225\n",
      "Result with TV: 0.7249706128732052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "print(\"Result with CV: {}\".format(do_check(CountVectorizer(), KNeighborsClassifier())))\n",
    "print(\"Result with TV: {}\".format(do_check(TfidfVectorizer(), KNeighborsClassifier())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result with CV: 0.6914841944299916\n",
      "Result with TV: 0.6664322497786753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(\"Result with CV: {}\".format(do_check(CountVectorizer(), DecisionTreeClassifier())))\n",
    "print(\"Result with TV: {}\".format(do_check(TfidfVectorizer(), DecisionTreeClassifier())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это просто :facepalm:. В общем если мы не хотим сразу переключаться на lstm и подобные решения (вообще есть сомнения по поводу того, что они могут тут сильно улучшить результат, данных очень мало), единственный способ хоть как -то улучшиться на этом этапе, это все же подбор гиперпатамертов (В дальнейшем можно попробовать поработать с данными, но пока интересно понять, что можно получить \"из коробки\").\n",
    "\n",
    "Сразу нужно уточнить, что на этапе baseline нам не интересно проводить глубокий анализ и потому мы просто возьмем лучшие результаты \"из коробки\" и для них уже будем пытаться проводить подбор параметров. Это частотность слов и методы опорных векторов, логистическая регрессия и стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv, clf = TfidfVectorizer(), LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "        ('vct', tv),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "        'vct__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "        'vct__ngram_range': ((1, 3), (1, 2)),\n",
    "        'clf__C': (0.00001, 0.0001, 0.01, 1),\n",
    "        'clf__penalty': ('l2', 'l1'),\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, scoring='accuracy', refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.7 s, sys: 132 ms, total: 39.8 s\n",
      "Wall time: 39.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vct', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vct__max_df': (0.25, 0.5, 0.75, 1.0), 'vct__ngram_range': ((1, 3), (1, 2)), 'clf__C': (1e-05, 0.0001, 0.01, 1), 'clf__penalty': ('l2', 'l1')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs.fit(df.sentences, df['p/n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__C: 1\n",
      "\tclf__penalty: 'l2'\n",
      "\tvct__max_df: 0.25\n",
      "\tvct__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "best_params = gs.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_params[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ну что, отличный результат. Настройка параметров помогла нам получить худший результат, чем на \"чистой\" моделе. Логистическая регрессия не показывает впечатляющих результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv, clf = TfidfVectorizer(), SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "        ('vct', tv),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "        'vct__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "        'vct__ngram_range': ((1, 3), (1, 2)),\n",
    "        'clf__alpha': (0.00001, 0.000001, 0.0000001, 0.00000001),\n",
    "        'clf__penalty': ('l2', 'elasticnet'),\n",
    "        'clf__n_iter': (10, 50, 80)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, scoring='accuracy', refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 56 ms, total: 2min 10s\n",
      "Wall time: 2min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vct', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vct__max_df': (0.25, 0.5, 0.75, 1.0), 'vct__ngram_range': ((1, 3), (1, 2)), 'clf__alpha': (1e-05, 1e-06, 1e-07, 1e-08), 'clf__penalty': ('l2', 'elasticnet'), 'clf__n_iter': (10, 50, 80)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs.fit(df.sentences, df['p/n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 1e-05\n",
      "\tclf__n_iter: 80\n",
      "\tclf__penalty: 'l2'\n",
      "\tvct__max_df: 1.0\n",
      "\tvct__ngram_range: (1, 3)\n",
      "Best score: 0.789\n"
     ]
    }
   ],
   "source": [
    "best_params = gs.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_params[param_name]))\n",
    "        \n",
    "print(\"Best score: {}\".format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь пусть и не значительно, но все же удалось улучшить результат. Можно попытаться перебирать больше параметров, но я не заметил существенных положительных изменений и не хотелось бы тратить много времени на этом этапе. Так же не вижу особого смысла в добавлении словаря без нормализации и токенизации текста, а просто добавление стоп слов не дает ощутимого эффекта. Поскольку решено пока на этапе baseline уделить больше внимания оценке разнообразных моделей с поверхностным подбором параметров без обработки данных, на этом и остановимся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv, clf = TfidfVectorizer(), LinearSVC()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "        ('vct', tv),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "        'vct__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "        'vct__ngram_range': ((1, 3), (1, 2)),\n",
    "        'clf__penalty': ('l2',), #  'l1'\n",
    "        'clf__loss': ('hinge',) # 'hinge', 'squared_hinge'\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, scoring='accuracy', refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.46 s, sys: 16 ms, total: 5.47 s\n",
      "Wall time: 5.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vct', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vct__max_df': (0.25, 0.5, 0.75, 1.0), 'vct__ngram_range': ((1, 3), (1, 2)), 'clf__penalty': ('l2',), 'clf__loss': ('hinge',)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs.fit(df.sentences, df['p/n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'l2'\n",
      "\tvct__max_df: 0.75\n",
      "\tvct__ngram_range: (1, 2)\n",
      "Best score: 0.7845\n"
     ]
    }
   ],
   "source": [
    "# with penalty=l2 and loss=squared_hingle == Best score: 0.7835\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_params[param_name]))\n",
    "        \n",
    "print(\"Best score: {}\".format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что не смотря на то, что \"из корбки\" стохастический градиент показывал худший результат, чем метод опорных векторов и логистическая регрессия, после базового подбора параметров он показывает лучший результат, а результат логистической регрессии вообще ухудшился.\n",
    "\n",
    "В итоге будем использовать для предсказаний вычисление частотности слов и стохастический градиент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно дополнительно попытаться нормальзовать матрицу <a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 536 ms, sys: 88 ms, total: 624 ms\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv, clf = TfidfVectorizer(sublinear_tf=True), SGDClassifier(random_state=113)\n",
    "trf = TfidfTransformer()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "        ('vct', tv),\n",
    "        ('tr', trf),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "# расчет занимает время, потому просто оставил оптимальные параметры\n",
    "parameters = {\n",
    "        'vct__max_df': (0.5,),\n",
    "        'vct__ngram_range': ((1, 3),),\n",
    "        'tr__norm': ('l2',),\n",
    "        'clf__alpha': (1e-05,),\n",
    "        'clf__penalty': ('l2',),\n",
    "        'clf__n_iter': (80, )\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, scoring='accuracy', refit=True, n_jobs=-1, iid=False, cv=10)\n",
    "gs.fit(df.sentences, df['p/n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 1e-05\n",
      "\tclf__n_iter: 80\n",
      "\tclf__penalty: 'l2'\n",
      "\ttr__norm: 'l2'\n",
      "\tvct__max_df: 0.5\n",
      "\tvct__ngram_range: (1, 3)\n",
      "Best score: 0.7974934373359334\n"
     ]
    }
   ],
   "source": [
    "best_params = gs.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_params[param_name]))\n",
    "        \n",
    "print(\"Best score: {}\".format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не значительно, но улучшился. На этом и остановимся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### подготовка сабмита <a id='1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predct = gs.predict(df_test.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for indx, elm in enumerate(predct):\n",
    "    result[indx] = elm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = pd.Series(result, name='y')\n",
    "subm.index.name = 'Id'\n",
    "subm = subm.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      "Id    500 non-null int64\n",
      "y     500 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "subm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv('submission.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/subm_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат ужасен и совершенно не интересен, с этим определенно нужно что -то делать!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Но что интересно, если мы перезапустим модель, результат меняется. Не смотря на то, что изменения в 3 знаке не несет никакой ценности, для kaggle это может быть полезно, поскольку дает + 15 мест.\n",
    "\n",
    "![title](img/subm_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "После небольшого тюнинга параметров имеем финальный результат. Основные изменения параметров, которые потребовались, для упрощения вынесенны в конструкторы классов, за пределы объекта параметров и могут быть изученны [тут](#2)\n",
    "\n",
    "![final](img/final.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь на изменение позиции в лидерборде повлияли параметры random_seed у SGDClassifier и подбор параметра cv у GridSearchCV. Так же параметр sublinear_tf=True у TfidfVectorizer, который по сути просто меняет скейлинг на $$ 1 + log(tf) $$ имеет значение и совокупность всех этих изменений, а возможно и просто случайность обеспечили последний результат. (как можно видеть из первых двух скриншотов, изменение позиции существенное, не смотря на то, что модель не изменялась)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно было заметить векторизация на основе частотности слов и стохастический градиент показали лучший результат: 0.7974934373359334. Результат на тесте естественно отличается и довольно существенно. Итоговый результат на kaggle 0.83750, что есть 19 место.\n",
    "\n",
    "В целом это простой baseline и модель требует серьезной доработки, поскольку результатом остался недоволен. Но на данном этапе этот результат приемлим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Возможно получиться сделать лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 404 ms, sys: 36 ms, total: 440 ms\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv, clf = TfidfVectorizer(sublinear_tf=True), SGDClassifier(random_state=113)\n",
    "trf = TfidfTransformer()\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "        ('vct', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "        ('tr', trf),\n",
    "        ('clf', LinearSVC(class_weight='balanced'))\n",
    "    ])\n",
    "# расчет занимает время, потому просто оставил оптимальные параметры\n",
    "parameters = {\n",
    "        'vct__max_df': (0.5,),\n",
    "        'vct__ngram_range': ((1, 3),),\n",
    "        'tr__norm': ('l2',),\n",
    "#         'clf__alpha': (1e-05,),\n",
    "#         'clf__penalty': ('l2',),\n",
    "#         'clf__n_iter': (80, )\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, scoring='accuracy', refit=True, n_jobs=-1, iid=False, cv=10)\n",
    "gs.fit(df.sentences, df['p/n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttr__norm: 'l2'\n",
      "\tvct__max_df: 0.5\n",
      "\tvct__ngram_range: (1, 3)\n",
      "Best score: 0.7939583864596614\n"
     ]
    }
   ],
   "source": [
    "best_params = gs.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_params[param_name]))\n",
    "        \n",
    "print(\"Best score: {}\".format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
